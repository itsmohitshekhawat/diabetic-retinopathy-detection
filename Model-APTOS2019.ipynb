{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a56a0d7",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ddd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d8d68",
   "metadata": {},
   "source": [
    "# Import CSV File with train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b48f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image  level\n",
      "0   10_left      0\n",
      "1  10_right      0\n",
      "2   13_left      0\n",
      "3  13_right      0\n",
      "4   15_left      1\n",
      "level\n",
      "0    25810\n",
      "2     5292\n",
      "1     2443\n",
      "3      873\n",
      "4      708\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"trainLabels.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Check the first few rows of the DataFrame to understand its structure\n",
    "print(df.head())\n",
    "\n",
    "# Check the distribution of the 'level' column\n",
    "print(df['level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0cbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder names\n",
    "folders = [\"No_DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferate_DR\"]\n",
    "\n",
    "# Creating subfolders\n",
    "base_directory = \"Dataset\"  # base directory\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_directory, folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f949081",
   "metadata": {},
   "source": [
    "## Arrange Images into Subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ae9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Load the CSV file from the directory \n",
    "csv_file = \"trainLabels.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Define the source directory for images\n",
    "source_directory = \"train\"  # Images are in the same directory as your notebook\n",
    "\n",
    "# Define the target directory for images with level 4 (Proliferate_DR) , similar prcodure applies for other classes\n",
    "target_directory = \"Dataset/Proliferate_DR\"\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# Iterate through the CSV data and copy images with level 4 to the target directory\n",
    "for index, row in df.iterrows():\n",
    "    image_name = row['image']\n",
    "    level = row['level']\n",
    "\n",
    "    if level == 4: #specify level here\n",
    "        source_path = os.path.join(source_directory, f\"{image_name}.jpeg\")\n",
    "        target_path = os.path.join(target_directory, f\"{image_name}.jpeg\")\n",
    "\n",
    "        # Copy the image to the Proliferate_DR folder\n",
    "        shutil.copy(source_path, target_path)\n",
    "\n",
    "print(\"Images with level 4 have been copied to the Proliferate_DR folder in the 'Dataset' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ecc27",
   "metadata": {},
   "source": [
    "# Resize all the images to fixed width and height of 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc230b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define the target size (224x224)\n",
    "target_size = (224, 224)\n",
    "\n",
    "# List of subfolders within the \"Dataset\" folder\n",
    "subfolders = [\"No_DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferate_DR\"]\n",
    "\n",
    "# Iterate through the subfolders and resize the images\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(\"Dataset\", subfolder)\n",
    "\n",
    "    for filename in os.listdir(subfolder_path):\n",
    "        if filename.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(subfolder_path, filename)\n",
    "            try:\n",
    "                # Open the image using OpenCV\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                # Resize the image to the target size\n",
    "                resized_image = cv2.resize(image, target_size)\n",
    "\n",
    "                # Save the resized image back to the original path\n",
    "                cv2.imwrite(image_path, resized_image)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {str(e)}\")\n",
    "\n",
    "print(\"Images in subfolders have been resized to 224x224 using OpenCV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d9f5c",
   "metadata": {},
   "source": [
    "# Normalize all the images in the subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# List of subfolders within the \"Dataset\" folder\n",
    "subfolders = [\"No_DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferate_DR\"]\n",
    "\n",
    "# Define the directory to store the normalized images\n",
    "normalized_folder = \"Normalized_Dataset\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(normalized_folder):\n",
    "    os.makedirs(normalized_folder)\n",
    "\n",
    "# Iterate through the subfolders and normalize the images\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(\"Dataset\", subfolder)\n",
    "    normalized_subfolder_path = os.path.join(normalized_folder, subfolder)\n",
    "\n",
    "    if not os.path.exists(normalized_subfolder_path):\n",
    "        os.makedirs(normalized_subfolder_path)\n",
    "\n",
    "    for filename in os.listdir(subfolder_path):\n",
    "        if filename.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(subfolder_path, filename)\n",
    "            try:\n",
    "                # Open the image using OpenCV\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Normalize the pixel values to the range [0, 1]\n",
    "                normalized_image = image / 255.0\n",
    "\n",
    "                # Define the path to save the normalized image in the normalized folder\n",
    "                normalized_image_path = os.path.join(normalized_subfolder_path, filename)\n",
    "\n",
    "                # Save the normalized image\n",
    "                cv2.imwrite(normalized_image_path, (normalized_image * 255.0).astype(int))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {str(e)}\")\n",
    "\n",
    "print(\"Images in subfolders have been normalized and saved in the 'Normalized_Dataset' folder using OpenCV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9166be",
   "metadata": {},
   "source": [
    "# Balance the dataset through data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# Specify the path to the main folder containing subfolders\n",
    "main_folder_path = \"Datasets/APTOS2019 Dataset/Augmented_Balanced Dataset_2\"\n",
    "\n",
    "# List of subfolders in the main folder\n",
    "subfolders = [\"Mild\", \"Moderate\", \"Severe\", \"Proliferate_DR\"]\n",
    "\n",
    "# Desired number of images per class\n",
    "desired_images_per_class = 1805\n",
    "\n",
    "# Augmentation configuration for ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Loop through each subfolder\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "\n",
    "    # List all image files in the subfolder\n",
    "    image_files = [f for f in os.listdir(subfolder_path) if f.endswith(\".png\")]  # Change the extension if needed\n",
    "\n",
    "    # Check if there are images in the subfolder\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {subfolder}. Skipping augmentation.\")\n",
    "        continue\n",
    "\n",
    "    # Calculate the number of images to augment\n",
    "    num_images_to_augment = max(0, desired_images_per_class - len(image_files))\n",
    "\n",
    "    # Augment images until the desired number is reached\n",
    "    for i in range(num_images_to_augment):\n",
    "        # Choose a random image file\n",
    "        original_image_path = os.path.join(subfolder_path, np.random.choice(image_files))\n",
    "\n",
    "        # Load the image\n",
    "        img = load_img(original_image_path)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        # Generate augmented images\n",
    "        for j, batch in enumerate(datagen.flow(x, batch_size=1)):\n",
    "            # Save augmented images using cv2.imwrite\n",
    "            augmented_image_path = os.path.join(subfolder_path, f\"augmented_image_{i * 5 + j + 1}.png\")\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(np.array(array_to_img(batch[0])), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # Plot the original image\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.subplot(1, 6, 1)\n",
    "            plt.imshow(array_to_img(batch[0]))\n",
    "            plt.title(\"Original Image\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Plot augmented images\n",
    "            for k in range(5):\n",
    "                plt.subplot(1, 6, k + 2)\n",
    "                plt.imshow(array_to_img(datagen.random_transform(x[0])))\n",
    "                plt.title(f\"Augmentation {k + 1}\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "            plt.show()\n",
    "            break  # Break the loop to generate only one set of augmented images\n",
    "\n",
    "print(\"Augmentation and Saving completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc78211",
   "metadata": {},
   "source": [
    "# Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5995928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42c009ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224 \n",
    "BATCH_SIZE = 40\n",
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd7a08",
   "metadata": {},
   "source": [
    "# Load the Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Datasets/APTOS2019 Dataset/Augmented_Balanced Dataset\",\n",
    "    shuffle=True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb11b38",
   "metadata": {},
   "source": [
    "# Visualize some images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde27c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for image_batch, label_batch in dataset.take(1):\n",
    "  for i in range(12):\n",
    "    ax = plt.subplot(3,4,i+1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[label_batch[i]])\n",
    "    plt.axis(\"Off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494f783",
   "metadata": {},
   "source": [
    "# Function for splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9afa0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "  ds_size = len(ds)\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(shuffle_size, seed=12)\n",
    "  train_size = int(train_split * ds_size)\n",
    "  val_size = int(val_split * ds_size)\n",
    "  train_ds = ds.take(train_size)\n",
    "  val_ds = ds.skip(train_size).take(val_size)\n",
    "  test_ds = ds.skip(train_size).take(val_size)\n",
    "  return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5bd2a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e913a82",
   "metadata": {},
   "source": [
    "# Defining preprocessing layer of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11e80546",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_rescale = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336717de",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8011fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    resize_rescale,\n",
    "    # Convolutional Block 1\n",
    "    layers.Conv2D(64, (3, 3), 1, activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # Convolutional Block 2\n",
    "    layers.Conv2D(128, (3, 3), 1, activation='relu'),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # Convolutional Block 3\n",
    "    layers.Conv2D(64, (3, 3), 1, activation='relu'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "     # Convolutional Block 4\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # Flatten and Fully Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    # Dropout Layer\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # Output Layer\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "model.build(input_shape=(32,IMAGE_SIZE,IMAGE_SIZE,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfefd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d7c07",
   "metadata": {},
   "source": [
    "# Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6c40893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161dd062",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd318efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802e020",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "723ae500",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(EPOCHS), acc, label = 'Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label = 'Validation Accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "#Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(EPOCHS), loss, label = 'Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label = 'Validation Loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Training and Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a93eeaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fad5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]]\n",
    "        plt.title(f\"Actual: {actual_class}. \\n Predicted: {predicted_class}. \\n Confidence: {confidence} %\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83331f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"Models/APTOS95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb20b6",
   "metadata": {},
   "source": [
    "# Classification Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e0f8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ = []\n",
    "pred_ = []\n",
    "temp = 0\n",
    "for images, labels in test_ds:\n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = labels[i]\n",
    "        true_.insert(i,actual_class)\n",
    "        temp = class_names.index(predicted_class)\n",
    "        pred_.insert(i, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663aeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_= np.array(true_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac717c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2457cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_, pred_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f84ee7",
   "metadata": {},
   "source": [
    "# Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(true_, pred_)\n",
    "\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
